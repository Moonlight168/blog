---
title: "从 MCP 到 Skills：大模型 Agent 的「工具 + 技能」双引擎"
date: 2026-01-29
---

# 从 MCP 到 Skills：解锁 Agent 的「工具 + 技能」双引擎

在 AI Agent 浪潮中，**MCP（模型上下文协议）** 和 **Skills（技能体系）** 是两大关键拼图。  
MCP 解决工具的**互联互通**，Skills 解决**如何高效使用工具**。  
两者结合，推动 Agent 能力大幅跃升。

## 一、为什么 LLM 不能直接调用工具，而 Agent 可以？

### LLM 和 Agent 的核心区别

- **LLM**：只有“大脑”。它擅长理解和生成文本，但**没有执行能力**。  
  例如让它“查北京天气”，它能告诉你用什么 API，却无法自己发请求。

- **Agent**：大脑 + 手脚 + 目标。  
  在 LLM 基础上加了**执行层**（运行代码、调用 API）和**目标驱动**（主动规划、迭代）。

### Agent 调用工具的真实分工

1. LLM 负责**思考和决策**：分析需求 → 决定调用哪个工具 → 输出工具名 + 参数。
2. 执行层负责**实际操作**：接收指令 → 发网络请求 / 跑代码 → 把结果返回给 LLM。
3. LLM 拿到结果后 → 整理成自然语言 → 回复用户。

### 为什么不让 LLM 直接执行工具？（三个关键原因）

1. **物理限制**：LLM 只是服务器上的数学模型，只能处理文本，没有网络、文件系统等“物理”能力。
2. **安全隔离**：直接执行代码风险极高（可能删文件、跑恶意命令）。  
   通过**沙箱 + 权限控制**，执行层把危险操作限制在安全范围内。
3. **模块化设计**：思考和执行分离，更清晰、更易维护、升级。

一句话总结：  
**LLM = 只会思考的模型**  
**Agent = 能思考 + 能执行 + 有目标的完整智能体**

MCP 的作用：让执行层用**统一标准**对接各种工具，避免为每个工具写一套代码。

## 二、MCP：让 Agent 的工具箱无限扩展

### MCP 是什么？

MCP（Model Context Protocol）是 Anthropic 于 2024 年 11 月推出的**开放标准协议**（现已获广泛采用）。  
它相当于 AI 领域的 **USB-C 接口**：  
让不同大模型（Claude、DeepSeek、Qwen 等）和各种工具（数据库、文件、API）实现**即插即用**，大幅降低集成成本。

### MCP 的协作角色（简单类比）

- LLM → 皇帝：只决策，不直接接触外部。
- Agent → 钦差：接收指令、调用工具、反馈结果。
- MCP → 标准化接口规范：让 Agent 轻松调用各种“地方工具”。

### 典型调用流程（以代码执行工具为例）

1. Agent 通过 MCP 获取可用工具列表（工具名、参数、描述）。
2. 用户提问 → Agent 把问题 + 工具列表发给 LLM。
3. LLM 选工具、生成参数 → Agent 通过 MCP 调用工具。
4. 工具执行 → 返回结果 → Agent 反馈给 LLM → LLM 整理回复用户。

### MCP 的价值与痛点

**价值**：
- 工具一次开发，多模型复用（Claude、开源模型都行）。
- 开发者容易做自定义工具（企业内部系统、私有数据）。

**痛点**：
工具太多时，每次请求都要传完整工具列表 → 消耗大量 Token（像每次点菜都给整本菜单）。

## 三、Skills：教 Agent “怎么做事”

MCP 解决“**有什么工具**”，Skills 解决“**怎么用好工具**”。

### Skills 是什么？

Skills 是**结构化的做事方法论**，本质是系统提示词的进阶版。  
它明确规定：在某场景下，**按什么顺序、调用什么工具、遵循什么逻辑**。

例如“代码审查 Skill”：
- 先调用静态分析工具查语法/漏洞
- 再用关键词检索知识库找历史解决方案
- 最后整理成报告

### Skills 的三大价值

1. **标准化流程**：把模糊需求变成清晰步骤，避免 Agent 乱试。
2. **沉淀领域知识**：把企业特有的运维/排查逻辑固化成可复用 Skill。
3. **降低 LLM 负担**：LLM 不用每次从零规划步骤，只需认可/微调 Skill 决策，效率显著提升。

### MCP + Skills 的协同

- MCP 提供**工具可达性**（能调用什么）
- Skills 提供**使用方法**（怎么组合、先后顺序）
- 两者叠加 → Agent 能力指数级增长

## 四、实战示例：代码审查 Agent

### 步骤 1：基于 MCP 开发工具

- 工具 A：代码静态分析（输入路径 → 输出漏洞列表）
- 工具 B：知识库检索（输入关键词 → 输出历史解法）

### 步骤 2：定义 CodeReview Skill

```text
触发条件：用户提交代码

执行步骤：
1. 调用 MCP 工具 A（静态分析），获取结果
2. 提取漏洞关键词
3. 对每个关键词调用 MCP 工具 B（知识库检索）
4. 整合结果，生成结构化报告
```

### 步骤 3：真实执行流程

用户上传代码 → 触发 Skill →  
LLM 决策调用工具 A → 执行 → 结果回来  
LLM 分析结果、提取关键词 → 决策调用工具 B → 执行 → 结果回来  
LLM 整合 → 输出报告

**关键点**：LLM 始终是**决策大脑**（选工具、分析结果、规划下一步），执行层 + MCP 负责**安全落地**。

## 五、未来：MCP + Skills 的可能性

- 垂直领域 Agent 大爆发（金融投研、医疗辅助诊断、法律合同审查等）
- 工具 + 技能生态化，像应用商店一样共享 MCP 工具和 Skill 模板

掌握 MCP（工具扩展） + Skills（流程设计），是打造下一代 Agent 的核心竞争力。

**一句话总结**：

LLM 提供智能核心，但缺“手脚”；  
Agent 通过**执行层 + MCP + Skills**补齐手脚、标准化工具接入和使用方法，最终成为能真正干活的完整智能体。


### 为什么既限制 LLM，又给它 Agent 和工具，然后只靠沙箱控制？

核心矛盾其实是**能力与安全的天平**：

- **不给工具** → LLM 再聪明也只能“纸上谈兵”，实用价值很低。
- **直接让 LLM 执行代码/网络请求** → 极度危险（越狱提示、生成恶意代码、泄露数据、删除文件等几乎不可避免）。
- **折中方案（当前主流）** → 给 LLM “思考 + 提需求”的权利，但**把执行权交给独立的、可严格受控的执行层**：
  - 执行层跑在**沙箱**里（网络、文件、系统调用都受限）
  - 每个工具调用都要经过**白名单、参数校验、用户确认**（很多产品会弹窗让用户批准）
  - MCP 这类协议进一步把工具标准化、集中管理，更容易在网关层加审计、限流、阻断等安全措施

换句话说：  
我们**想要 LLM 的理解力和规划力**，但**不信任它有物理破坏力**。  
所以才设计了“**大脑放飞，双手戴铐**”的架构——Agent 就是这个“戴着手铐但能干活”的折中产物。
